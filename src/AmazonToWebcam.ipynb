{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AmazonToWebcam.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9Ce77R8CZfNF",
        "kbYF-215M8lf",
        "WwIfvkiZRXxJ"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdjeTu_gnI1h",
        "outputId": "c0cd92d3-41c4-4105-cc9f-fdc631e408c4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Feb  1 11:22:46 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  GeForce RTX 208...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
            "| 27%   36C    P8    21W / 250W |  10490MiB / 10989MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
            "| 27%   33C    P8     9W / 250W |   1639MiB / 10989MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   2  GeForce RTX 208...  Off  | 00000000:3D:00.0 Off |                  N/A |\n",
            "| 27%   31C    P8     4W / 250W |   1639MiB / 10989MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   3  GeForce RTX 208...  Off  | 00000000:3E:00.0 Off |                  N/A |\n",
            "| 27%   33C    P8    14W / 250W |   1639MiB / 10989MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   4  GeForce RTX 208...  Off  | 00000000:88:00.0 Off |                  N/A |\n",
            "| 27%   30C    P8     3W / 250W |   1639MiB / 10989MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   5  GeForce RTX 208...  Off  | 00000000:89:00.0 Off |                  N/A |\n",
            "| 27%   34C    P8    22W / 250W |   1639MiB / 10989MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   6  GeForce RTX 208...  Off  | 00000000:B1:00.0 Off |                  N/A |\n",
            "| 27%   34C    P8    22W / 250W |   1639MiB / 10989MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   7  GeForce RTX 208...  Off  | 00000000:B2:00.0 Off |                  N/A |\n",
            "| 27%   31C    P8    14W / 250W |   1639MiB / 10989MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf4A3J8ZBezF"
      },
      "source": [
        "# !tar -xf \"/content/drive/MyDrive/gitLab/datasets/domain_adaptation_images.tar.gz\" -C \"/content/drive/MyDrive/gitLab/datasets/office\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrQW0vGM5dJv",
        "outputId": "9b1941bf-b8b4-4253-caa8-2ccce9393c65"
      },
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "# base_dir = '/root/Master-Thesis'\n",
        "# os.chdir(base_dir)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/Master-Thesis/src'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRszWV2H5dJx"
      },
      "source": [
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "# import tensorflow_model_optimization as tfmot\n",
        "# import tensorflow_probability as tfp\n",
        "import zipfile\n",
        "import pickle\n",
        "import datetime\n",
        "import os\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "# tf.random.set_seed(100)\n",
        "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
        "initializer = tf.keras.initializers.he_normal()\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from tensorflow.keras import layers\n",
        "import seaborn as sns\n",
        "import bokeh"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kenFF2N75dJy",
        "outputId": "949b463f-ad04-4fbd-8c2a-6fad3b56780e"
      },
      "source": [
        "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "import pandas as pd\n",
        "physical_devices"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXK4O9Hw5dJ1"
      },
      "source": [
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_path = r\"/root/Master-Thesis2/code/logs/5_Xception_SourceOnly/20210301-074025/training_logs.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "logdd = pd.read_csv(log_path,sep=\";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    epoch  accuracy      loss  val_accuracy  val_loss\n",
              "0       0   0.79990  0.692879      0.649927  1.561941\n",
              "1       1   0.90773  0.303110      0.680711  1.504924\n",
              "2       2   0.92021  0.261052      0.630493  1.848594\n",
              "3       3   0.92686  0.238628      0.625112  2.057047\n",
              "4       4   0.93665  0.202673      0.657222  1.882489\n",
              "5       5   0.93965  0.193529      0.692520  1.698546\n",
              "6       6   0.94184  0.184053      0.669464  2.073504\n",
              "7       7   0.94339  0.181208      0.688974  2.026242\n",
              "8       8   0.94562  0.169851      0.688184  2.005179\n",
              "9       9   0.94622  0.168823      0.670407  2.232765\n",
              "10     10   0.94871  0.159203      0.698692  1.991409\n",
              "11     11   0.94908  0.160125      0.631309  2.623911\n",
              "12     12   0.94953  0.156536      0.679691  2.257696\n",
              "13     13   0.95040  0.155372      0.648525  2.565523\n",
              "14     14   0.95034  0.155963      0.666250  2.366760\n",
              "15     15   0.95070  0.154405      0.677345  2.304312\n",
              "16     16   0.94971  0.155528      0.688770  2.198900\n",
              "17     17   0.95063  0.154536      0.664669  2.429764"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch</th>\n      <th>accuracy</th>\n      <th>loss</th>\n      <th>val_accuracy</th>\n      <th>val_loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.79990</td>\n      <td>0.692879</td>\n      <td>0.649927</td>\n      <td>1.561941</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.90773</td>\n      <td>0.303110</td>\n      <td>0.680711</td>\n      <td>1.504924</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.92021</td>\n      <td>0.261052</td>\n      <td>0.630493</td>\n      <td>1.848594</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.92686</td>\n      <td>0.238628</td>\n      <td>0.625112</td>\n      <td>2.057047</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.93665</td>\n      <td>0.202673</td>\n      <td>0.657222</td>\n      <td>1.882489</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0.93965</td>\n      <td>0.193529</td>\n      <td>0.692520</td>\n      <td>1.698546</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>0.94184</td>\n      <td>0.184053</td>\n      <td>0.669464</td>\n      <td>2.073504</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>0.94339</td>\n      <td>0.181208</td>\n      <td>0.688974</td>\n      <td>2.026242</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>0.94562</td>\n      <td>0.169851</td>\n      <td>0.688184</td>\n      <td>2.005179</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>0.94622</td>\n      <td>0.168823</td>\n      <td>0.670407</td>\n      <td>2.232765</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>0.94871</td>\n      <td>0.159203</td>\n      <td>0.698692</td>\n      <td>1.991409</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>0.94908</td>\n      <td>0.160125</td>\n      <td>0.631309</td>\n      <td>2.623911</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>0.94953</td>\n      <td>0.156536</td>\n      <td>0.679691</td>\n      <td>2.257696</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>0.95040</td>\n      <td>0.155372</td>\n      <td>0.648525</td>\n      <td>2.565523</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>0.95034</td>\n      <td>0.155963</td>\n      <td>0.666250</td>\n      <td>2.366760</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>0.95070</td>\n      <td>0.154405</td>\n      <td>0.677345</td>\n      <td>2.304312</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>0.94971</td>\n      <td>0.155528</td>\n      <td>0.688770</td>\n      <td>2.198900</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>0.95063</td>\n      <td>0.154536</td>\n      <td>0.664669</td>\n      <td>2.429764</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "logdd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 2 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"266.0675pt\" version=\"1.1\" viewBox=\"0 0 436.4675 266.0675\" width=\"436.4675pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-03-01T22:30:42.167139</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 266.0675 \nL 436.4675 266.0675 \nL 436.4675 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 54.015 224.64 \nL 388.815 224.64 \nL 388.815 7.2 \nL 54.015 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mfd4039d9b4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.233182\" xlink:href=\"#mfd4039d9b4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <g transform=\"translate(61.281619 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"113.99254\" xlink:href=\"#mfd4039d9b4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2.5 -->\n      <g transform=\"translate(106.040978 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"158.751898\" xlink:href=\"#mfd4039d9b4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 5.0 -->\n      <g transform=\"translate(150.800336 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"203.511257\" xlink:href=\"#mfd4039d9b4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 7.5 -->\n      <g transform=\"translate(195.559694 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"248.270615\" xlink:href=\"#mfd4039d9b4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 10.0 -->\n      <g transform=\"translate(237.137802 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"293.029973\" xlink:href=\"#mfd4039d9b4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 12.5 -->\n      <g transform=\"translate(281.897161 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"337.789332\" xlink:href=\"#mfd4039d9b4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 15.0 -->\n      <g transform=\"translate(326.656519 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"382.54869\" xlink:href=\"#mfd4039d9b4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 17.5 -->\n      <g transform=\"translate(371.415877 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_9\">\n     <!-- Epochs -->\n     <g transform=\"translate(196.333125 255.955938)scale(0.14 -0.14)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"306.201172\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"me9d3b8c7a2\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.015\" xlink:href=\"#me9d3b8c7a2\" y=\"199.645992\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.65 -->\n      <g transform=\"translate(24.749375 203.445211)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.015\" xlink:href=\"#me9d3b8c7a2\" y=\"169.289762\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.70 -->\n      <g transform=\"translate(24.749375 173.088981)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.015\" xlink:href=\"#me9d3b8c7a2\" y=\"138.933533\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.75 -->\n      <g transform=\"translate(24.749375 142.732751)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.015\" xlink:href=\"#me9d3b8c7a2\" y=\"108.577303\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.80 -->\n      <g transform=\"translate(24.749375 112.376522)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.015\" xlink:href=\"#me9d3b8c7a2\" y=\"78.221074\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.85 -->\n      <g transform=\"translate(24.749375 82.020292)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.015\" xlink:href=\"#me9d3b8c7a2\" y=\"47.864844\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.90 -->\n      <g transform=\"translate(24.749375 51.664063)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.015\" xlink:href=\"#me9d3b8c7a2\" y=\"17.508614\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.95 -->\n      <g transform=\"translate(24.749375 21.307833)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- Accuracy -->\n     <g style=\"fill:#ff0000;\" transform=\"translate(17.837813 147.879375)rotate(-90)scale(0.14 -0.14)\">\n      <defs>\n       <path d=\"M 34.1875 63.1875 \nL 20.796875 26.90625 \nL 47.609375 26.90625 \nz\nM 28.609375 72.90625 \nL 39.796875 72.90625 \nL 67.578125 0 \nL 57.328125 0 \nL 50.6875 18.703125 \nL 17.828125 18.703125 \nL 11.1875 0 \nL 0.78125 0 \nz\n\" id=\"DejaVuSans-65\"/>\n       <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"121.638672\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"176.619141\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"239.998047\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"281.111328\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"342.390625\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"397.371094\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#pc146b28346)\" d=\"M 69.233182 108.638018 \nL 87.136925 43.171781 \nL 105.040668 35.594854 \nL 122.944412 31.557493 \nL 140.848155 25.613741 \nL 158.751898 23.792355 \nL 176.655642 22.462755 \nL 194.559385 21.521701 \nL 212.463128 20.16782 \nL 230.366872 19.803557 \nL 248.270615 18.29179 \nL 266.174358 18.067175 \nL 284.078102 17.79396 \nL 301.981845 17.265768 \nL 319.885588 17.302209 \nL 337.789332 17.083636 \nL 355.693075 17.684674 \nL 373.596818 17.12612 \n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m008520e5b8\" style=\"stroke:#ff0000;\"/>\n    </defs>\n    <g clip-path=\"url(#pc146b28346)\">\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"69.233182\" xlink:href=\"#m008520e5b8\" y=\"108.638018\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"87.136925\" xlink:href=\"#m008520e5b8\" y=\"43.171781\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"105.040668\" xlink:href=\"#m008520e5b8\" y=\"35.594854\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"122.944412\" xlink:href=\"#m008520e5b8\" y=\"31.557493\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"140.848155\" xlink:href=\"#m008520e5b8\" y=\"25.613741\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"158.751898\" xlink:href=\"#m008520e5b8\" y=\"23.792355\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"176.655642\" xlink:href=\"#m008520e5b8\" y=\"22.462755\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"194.559385\" xlink:href=\"#m008520e5b8\" y=\"21.521701\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"212.463128\" xlink:href=\"#m008520e5b8\" y=\"20.16782\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"230.366872\" xlink:href=\"#m008520e5b8\" y=\"19.803557\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"248.270615\" xlink:href=\"#m008520e5b8\" y=\"18.29179\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"266.174358\" xlink:href=\"#m008520e5b8\" y=\"18.067175\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"284.078102\" xlink:href=\"#m008520e5b8\" y=\"17.79396\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"301.981845\" xlink:href=\"#m008520e5b8\" y=\"17.265768\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"319.885588\" xlink:href=\"#m008520e5b8\" y=\"17.302209\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"337.789332\" xlink:href=\"#m008520e5b8\" y=\"17.083636\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"355.693075\" xlink:href=\"#m008520e5b8\" y=\"17.684674\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"373.596818\" xlink:href=\"#m008520e5b8\" y=\"17.12612\"/>\n    </g>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#pc146b28346)\" d=\"M 69.233182 199.690119 \nL 87.136925 181.000533 \nL 105.040668 211.48918 \nL 122.944412 214.756364 \nL 140.848155 195.261608 \nL 158.751898 173.83133 \nL 176.655642 187.829141 \nL 194.559385 175.983615 \nL 212.463128 176.463641 \nL 230.366872 187.256221 \nL 248.270615 170.08412 \nL 266.174358 210.993665 \nL 284.078102 181.619918 \nL 301.981845 200.541754 \nL 319.885588 189.780151 \nL 337.789332 183.044473 \nL 355.693075 176.10752 \nL 373.596818 190.740204 \n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n    <g clip-path=\"url(#pc146b28346)\">\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"69.233182\" xlink:href=\"#m008520e5b8\" y=\"199.690119\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"87.136925\" xlink:href=\"#m008520e5b8\" y=\"181.000533\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"105.040668\" xlink:href=\"#m008520e5b8\" y=\"211.48918\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"122.944412\" xlink:href=\"#m008520e5b8\" y=\"214.756364\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"140.848155\" xlink:href=\"#m008520e5b8\" y=\"195.261608\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"158.751898\" xlink:href=\"#m008520e5b8\" y=\"173.83133\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"176.655642\" xlink:href=\"#m008520e5b8\" y=\"187.829141\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"194.559385\" xlink:href=\"#m008520e5b8\" y=\"175.983615\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"212.463128\" xlink:href=\"#m008520e5b8\" y=\"176.463641\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"230.366872\" xlink:href=\"#m008520e5b8\" y=\"187.256221\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"248.270615\" xlink:href=\"#m008520e5b8\" y=\"170.08412\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"266.174358\" xlink:href=\"#m008520e5b8\" y=\"210.993665\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"284.078102\" xlink:href=\"#m008520e5b8\" y=\"181.619918\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"301.981845\" xlink:href=\"#m008520e5b8\" y=\"200.541754\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"319.885588\" xlink:href=\"#m008520e5b8\" y=\"189.780151\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"337.789332\" xlink:href=\"#m008520e5b8\" y=\"183.044473\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"355.693075\" xlink:href=\"#m008520e5b8\" y=\"176.10752\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"373.596818\" xlink:href=\"#m008520e5b8\" y=\"190.740204\"/>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 54.015 224.64 \nL 54.015 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 388.815 224.64 \nL 388.815 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 54.015 224.64 \nL 388.815 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 54.015 7.2 \nL 388.815 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"ytick_8\">\n     <g id=\"line2d_18\">\n      <defs>\n       <path d=\"M 0 0 \nL 3.5 0 \n\" id=\"mbe1fa65ac8\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"388.815\" xlink:href=\"#mbe1fa65ac8\" y=\"187.093041\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 0.5 -->\n      <g transform=\"translate(395.815 190.89226)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_19\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"388.815\" xlink:href=\"#mbe1fa65ac8\" y=\"147.070325\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 1.0 -->\n      <g transform=\"translate(395.815 150.869543)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"388.815\" xlink:href=\"#mbe1fa65ac8\" y=\"107.047609\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 1.5 -->\n      <g transform=\"translate(395.815 110.846827)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_21\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"388.815\" xlink:href=\"#mbe1fa65ac8\" y=\"67.024893\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 2.0 -->\n      <g transform=\"translate(395.815 70.824111)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"388.815\" xlink:href=\"#mbe1fa65ac8\" y=\"27.002176\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- 2.5 -->\n      <g transform=\"translate(395.815 30.801395)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_23\">\n     <!-- Loss -->\n     <g style=\"fill:#ff0000;\" transform=\"translate(426.355937 131.274062)rotate(-90)scale(0.14 -0.14)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 8.296875 \nL 55.171875 8.296875 \nL 55.171875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-76\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_23\">\n    <path clip-path=\"url(#pc146b28346)\" d=\"M 69.233182 171.653928 \nL 87.136925 202.853171 \nL 105.040668 206.219738 \nL 122.944412 208.014653 \nL 140.848155 210.892711 \nL 158.751898 211.624664 \nL 176.655642 212.383171 \nL 194.559385 212.610845 \nL 212.463128 213.519923 \nL 230.366872 213.602267 \nL 248.270615 214.372305 \nL 266.174358 214.298495 \nL 284.078102 214.585727 \nL 301.981845 214.678934 \nL 319.885588 214.631629 \nL 337.789332 214.756364 \nL 355.693075 214.666426 \nL 373.596818 214.745873 \n\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"mabea84a719\" style=\"stroke:#008000;\"/>\n    </defs>\n    <g clip-path=\"url(#pc146b28346)\">\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"69.233182\" xlink:href=\"#mabea84a719\" y=\"171.653928\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"87.136925\" xlink:href=\"#mabea84a719\" y=\"202.853171\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"105.040668\" xlink:href=\"#mabea84a719\" y=\"206.219738\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"122.944412\" xlink:href=\"#mabea84a719\" y=\"208.014653\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"140.848155\" xlink:href=\"#mabea84a719\" y=\"210.892711\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"158.751898\" xlink:href=\"#mabea84a719\" y=\"211.624664\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"176.655642\" xlink:href=\"#mabea84a719\" y=\"212.383171\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"194.559385\" xlink:href=\"#mabea84a719\" y=\"212.610845\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"212.463128\" xlink:href=\"#mabea84a719\" y=\"213.519923\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"230.366872\" xlink:href=\"#mabea84a719\" y=\"213.602267\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"248.270615\" xlink:href=\"#mabea84a719\" y=\"214.372305\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"266.174358\" xlink:href=\"#mabea84a719\" y=\"214.298495\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"284.078102\" xlink:href=\"#mabea84a719\" y=\"214.585727\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"301.981845\" xlink:href=\"#mabea84a719\" y=\"214.678934\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"319.885588\" xlink:href=\"#mabea84a719\" y=\"214.631629\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"337.789332\" xlink:href=\"#mabea84a719\" y=\"214.756364\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"355.693075\" xlink:href=\"#mabea84a719\" y=\"214.666426\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"373.596818\" xlink:href=\"#mabea84a719\" y=\"214.745873\"/>\n    </g>\n   </g>\n   <g id=\"line2d_24\">\n    <path clip-path=\"url(#pc146b28346)\" d=\"M 69.233182 102.08955 \nL 87.136925 106.653498 \nL 105.040668 79.144246 \nL 122.944412 62.45855 \nL 140.848155 76.431085 \nL 158.751898 91.154875 \nL 176.655642 61.141254 \nL 194.559385 64.924301 \nL 212.463128 66.610362 \nL 230.366872 48.39314 \nL 248.270615 67.712558 \nL 266.174358 17.083636 \nL 284.078102 46.397474 \nL 301.981845 21.757367 \nL 319.885588 37.667429 \nL 337.789332 42.666089 \nL 355.693075 51.103857 \nL 373.596818 32.624264 \n\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n    <g clip-path=\"url(#pc146b28346)\">\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"69.233182\" xlink:href=\"#mabea84a719\" y=\"102.08955\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"87.136925\" xlink:href=\"#mabea84a719\" y=\"106.653498\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"105.040668\" xlink:href=\"#mabea84a719\" y=\"79.144246\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"122.944412\" xlink:href=\"#mabea84a719\" y=\"62.45855\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"140.848155\" xlink:href=\"#mabea84a719\" y=\"76.431085\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"158.751898\" xlink:href=\"#mabea84a719\" y=\"91.154875\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"176.655642\" xlink:href=\"#mabea84a719\" y=\"61.141254\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"194.559385\" xlink:href=\"#mabea84a719\" y=\"64.924301\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"212.463128\" xlink:href=\"#mabea84a719\" y=\"66.610362\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"230.366872\" xlink:href=\"#mabea84a719\" y=\"48.39314\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"248.270615\" xlink:href=\"#mabea84a719\" y=\"67.712558\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"266.174358\" xlink:href=\"#mabea84a719\" y=\"17.083636\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"284.078102\" xlink:href=\"#mabea84a719\" y=\"46.397474\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"301.981845\" xlink:href=\"#mabea84a719\" y=\"21.757367\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"319.885588\" xlink:href=\"#mabea84a719\" y=\"37.667429\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"337.789332\" xlink:href=\"#mabea84a719\" y=\"42.666089\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"355.693075\" xlink:href=\"#mabea84a719\" y=\"51.103857\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"373.596818\" xlink:href=\"#mabea84a719\" y=\"32.624264\"/>\n    </g>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 54.015 224.64 \nL 54.015 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 388.815 224.64 \nL 388.815 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 54.015 224.64 \nL 388.815 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 54.015 7.2 \nL 388.815 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc146b28346\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"54.015\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# create figure and axis objects with subplots()\n",
        "fig,ax = plt.subplots()\n",
        "# make a plot\n",
        "ax.plot(logdd.epoch, logdd.accuracy, color=\"red\", marker=\"o\")\n",
        "ax.plot(logdd.epoch, logdd.val_accuracy,color=\"red\",marker=\"o\")\n",
        "# set x-axis label\n",
        "ax.set_xlabel(\"Epochs\",fontsize=14)\n",
        "# set y-axis label\n",
        "ax.set_ylabel(\"Accuracy\",color=\"red\",fontsize=14)\n",
        "\n",
        "ax2=ax.twinx()\n",
        "ax2.plot(logdd.epoch, logdd.loss,color=\"green\",marker=\"o\")\n",
        "ax2.plot(logdd.epoch, logdd.val_loss,color=\"green\",marker=\"o\")\n",
        "ax2.set_ylabel(\"Loss\",color=\"Red\",fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9soVBQIW-Qm"
      },
      "source": [
        "initializer = tf.keras.initializers.he_normal()  # Layer initializations\n",
        "BASE_DIR = Path(\"/root/Master-Thesis/code\")\n",
        "MNIST_M_PATH = BASE_DIR / Path(\"data/keras_mnistm.pkl\")\n",
        "OFFICE_DS_PATH = BASE_DIR / Path(\"data/office/\")\n",
        "LOGS_DIR = BASE_DIR / Path(\"logs/\")  # Logs path\n",
        "MODEL_PATH = BASE_DIR / Path(\"model_data/\")  # Model path\n",
        "EVALUATION = BASE_DIR / Path(\"evaluation/\")  # Evalaution plots path\n",
        "PRETRAINED_WEIGHTS = BASE_DIR / Path(\"pretrained_weights\")\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "DATASET_COMBINATION = {\n",
        "    \"Amazon_to_Webcam\": 1,\n",
        "    \"Amazon_to_DSLR\": 2,\n",
        "    \"Webcam_to_Amazon\": 3,\n",
        "    \"Webcam_to_DSLR\": 4,\n",
        "    \"DSLR_to_Amazon\": 5,\n",
        "    \"DSLR_to_Webcam\": 6,\n",
        "    \"MNIST_to_MNISTM\": 7,\n",
        "    \"MNISTM_to_MNIST\": 8,\n",
        "    \"SynSigns_to_GTSRB\": 9,\n",
        "    \"GTSRB_to_SynSigns\": 10,\n",
        "}\n",
        "\n",
        "Loss = {1: \"CORAL\", 2: \"Other\"}\n",
        "\n",
        "# pruning_params = {\n",
        "#     \"pruning_schedule\": tfmot.sparsity.keras.ConstantSparsity(\n",
        "#         0.20, 0, end_step=-1, frequency=1\n",
        "#     )\n",
        "# }\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PP2h7ibZIvs"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grPjg57GnKuH"
      },
      "source": [
        "source_directory = OFFICE_DS_PATH / \"amazon\"\n",
        "target_directory = OFFICE_DS_PATH / \"webcam\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/Master-Thesis/code/data/office/amazon')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "source_directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMC-rFm0m7CS"
      },
      "source": [
        "# def create_paths(path):\n",
        "#     all_image_paths = [str(path) for path in list(path.glob(\"*/*\"))]\n",
        "#     label_names = sorted(item.name for item in path.glob(\"*/\") if item.is_dir())\n",
        "#     label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
        "\n",
        "#     all_image_labels = [\n",
        "#         label_to_index[Path(path).parent.name] for path in all_image_paths\n",
        "#     ]\n",
        "\n",
        "#     return all_image_paths, all_image_labels"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOgS3dfdn65y"
      },
      "source": [
        "# source_images_list, source_labels_list = create_paths(source_directory)\n",
        "# target_images_list, target_labels_list = create_paths(target_directory)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NFW9AuUoRgC"
      },
      "source": [
        "# def read_images(file, label):\n",
        "#     image = tf.io.read_file(file)\n",
        "#     image = tf.image.decode_jpeg(image, channels=3)\n",
        "#     image = tf.cast(image, tf.float32)\n",
        "#     image = tf.keras.applications.vgg16.preprocess_input(image)\n",
        "#     image = tf.image.resize(image, [227, 227], method=\"nearest\")\n",
        "#     # image = image / 255.0\n",
        "#     return image, label"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2817 files belonging to 31 classes.\n"
          ]
        }
      ],
      "source": [
        "source_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  source_directory,\n",
        "  validation_split=0,\n",
        "  image_size=(227, 227),\n",
        "  batch_size=16,\n",
        "  labels=\"inferred\",\n",
        "  interpolation=\"nearest\",\n",
        "  label_mode = \"categorical\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['back_pack',\n",
              " 'bike',\n",
              " 'bike_helmet',\n",
              " 'bookcase',\n",
              " 'bottle',\n",
              " 'calculator',\n",
              " 'desk_chair',\n",
              " 'desk_lamp',\n",
              " 'desktop_computer',\n",
              " 'file_cabinet',\n",
              " 'headphones',\n",
              " 'keyboard',\n",
              " 'laptop_computer',\n",
              " 'letter_tray',\n",
              " 'mobile_phone',\n",
              " 'monitor',\n",
              " 'mouse',\n",
              " 'mug',\n",
              " 'paper_notebook',\n",
              " 'pen',\n",
              " 'phone',\n",
              " 'printer',\n",
              " 'projector',\n",
              " 'punchers',\n",
              " 'ring_binder',\n",
              " 'ruler',\n",
              " 'scissors',\n",
              " 'speaker',\n",
              " 'stapler',\n",
              " 'tape_dispenser',\n",
              " 'trash_can']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "source_ds.class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 720x720 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"174.282353pt\" version=\"1.1\" viewBox=\"0 0 174.282353 174.282353\" width=\"174.282353pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-01-24T11:37:03.317750</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 174.282353 \nL 174.282353 174.282353 \nL 174.282353 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g clip-path=\"url(#pe26d39b410)\">\n    <image height=\"160\" id=\"imagea40f4ba0ef\" transform=\"scale(1 -1)translate(0 -160)\" width=\"160\" x=\"7.2\" xlink:href=\"data:image/png;base64,\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\" y=\"-7.082353\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe26d39b410\">\n   <rect height=\"159.882353\" width=\"159.882353\" x=\"7.2\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in source_ds.take(1):\n",
        "  for i in range(1):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    # plt.title(source_ds.class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRWaA5eQYCU8"
      },
      "source": [
        "def augment_ds(image, label):\n",
        "\n",
        "    # Make Images Greyscale\n",
        "    image = tf.cond(\n",
        "        tf.random.uniform(shape=[], minval=0, maxval=1) < 0.4,\n",
        "        lambda: tf.tile(tf.image.rgb_to_grayscale(image), [1, 1, 1, 3]),\n",
        "        lambda: image,\n",
        "    )\n",
        "\n",
        "    # Adding Gaussian Noise\n",
        "    noise = tf.random.normal(\n",
        "        shape=tf.shape(image), mean=0.0, stddev=1, dtype=tf.float32\n",
        "    )\n",
        "    image = tf.cond(\n",
        "        tf.random.uniform(shape=[], minval=0, maxval=1) < 0.4,\n",
        "        lambda: tf.add(image, noise),\n",
        "        lambda: image,\n",
        "    )\n",
        "\n",
        "    # Colour Augmentations\n",
        "    image = tf.image.random_hue(image, 0.08)\n",
        "    image = tf.image.random_saturation(image, 2, 5)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.4)\n",
        "    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)\n",
        "\n",
        "    # Rotating Images\n",
        "    image = tf.cond(\n",
        "        tf.random.uniform(shape=[], minval=0, maxval=1) < 0.4,\n",
        "        lambda: tf.image.rot90(image, k=1),\n",
        "        lambda: tf.image.rot90(image, k=3),\n",
        "    )\n",
        "\n",
        "    # Flipping Images\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "\n",
        "    return image, label"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(image, label):\n",
        "    # Cast to float32\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
        "    image = image / 255.0\n",
        "\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_images(source_directory, batch_size, new_size):\n",
        "    ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        source_directory,\n",
        "        labels=\"inferred\",\n",
        "        label_mode=\"int\",  # categorical, binary\n",
        "        batch_size=batch_size,\n",
        "        image_size=(new_size, new_size),  # reshape if not in this size\n",
        "        shuffle=True,\n",
        "    )\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2817 files belonging to 31 classes.\n"
          ]
        }
      ],
      "source": [
        "source_ds = read_images(source_directory, 16, 227)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "177"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "source_ds.cardinality().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "source_ds= source_ds.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "source_ds = source_ds.map(augment_ds, num_parallel_calls=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "aa = next(iter(source_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "a1 = tf.keras.applications.xception.preprocess_input(aa[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "np.min(np.array(a1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 795 files belonging to 31 classes.\n"
          ]
        }
      ],
      "source": [
        "target_ds_original = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  target_directory,\n",
        "  validation_split=0,\n",
        "  image_size=(227, 227),\n",
        "  batch_size=16,\n",
        "  labels=\"inferred\",\n",
        "  interpolation=\"nearest\",\n",
        "  label_mode = \"categorical\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wws4HoY4YdJ8"
      },
      "source": [
        "target_ds = target_ds_original.repeat(4)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_ds = target_ds.map(preprocess).unbatch()\n",
        "# target_ds = target_ds.map(preprocess).cache().shuffle(795).unbatch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_UnbatchDataset shapes: ((227, 227, 3), (31,)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "target_ds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lrW-PsvoUsz"
      },
      "source": [
        "  source_images, target_images, source_labels, target_labels = [], [], [], []\n",
        "  for x, y in tf.data.Dataset.zip((source_ds, target_ds)):\n",
        "      source_images.append(x[0])\n",
        "      target_images.append(y[0])\n",
        "      source_labels.append(x[1])\n",
        "      target_labels.append(y[1])\n",
        "\n",
        "  ds_train = tf.data.Dataset.from_tensor_slices(\n",
        "        ((source_images, target_images), source_labels)\n",
        "    )\n",
        "  ds_train = ds_train.batch(32).prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Shapes of all inputs must match: values[0].shape = [16,227,227,3] != values[176].shape = [1,227,227,3] [Op:Pack] name: component_0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-6660158018de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtarget_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m ds_train = tf.data.Dataset.from_tensor_slices(\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   )\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \"\"\"\n\u001b[0;32m--> 682\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   2999\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m           normalized_components.append(\n\u001b[0;32m--> 115\u001b[0;31m               ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[1;32m    116\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1500\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m   1406\u001b[0m     \u001b[0;31m# checking.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_or_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_or_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m   \u001b[0mmust_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m   \u001b[0mconverted_elems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   6457\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6458\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6459\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6461\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes of all inputs must match: values[0].shape = [16,227,227,3] != values[176].shape = [1,227,227,3] [Op:Pack] name: component_0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aa[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exnlh_2LPCiy"
      },
      "source": [
        "x1, y1 = [], []\n",
        "for x, y in target_ds_original.map(preprocess, num_parallel_calls=AUTOTUNE).unbatch():\n",
        "    x1.append(x)\n",
        "    y1.append(y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_test = (\n",
        "    tf.data.Dataset.from_tensor_slices(((x1, x1), y1))\n",
        "    .batch(32)\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bb = next(iter(ds_test))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkih0UI2Y8Hk"
      },
      "source": [
        "train_count = [x for x in ds_train]\r\n",
        "print(f\"Batch count of training set: {str(len(train_count))}\")\r\n",
        "\r\n",
        "test_count = [x for x in ds_test]\r\n",
        "print(f\"Batch count of test set: {str(len(test_count))}\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch count of training set: 89\n",
            "Batch count of test set: 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK9lhFsYvRCO"
      },
      "source": [
        "## Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "base_model = tf.keras.applications.Xception(\n",
        "    include_top=False, weights=\"imagenet\", input_shape=(299,299,3), pooling=\"avg\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_27 (Add)                    (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n                                                                 add_26[0][0]                     \n__________________________________________________________________________________________________\nblock6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_27[0][0]                     \n__________________________________________________________________________________________________\nblock6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_28 (Add)                    (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n                                                                 add_27[0][0]                     \n__________________________________________________________________________________________________\nblock7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_28[0][0]                     \n__________________________________________________________________________________________________\nblock7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_29 (Add)                    (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n                                                                 add_28[0][0]                     \n__________________________________________________________________________________________________\nblock8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_29[0][0]                     \n__________________________________________________________________________________________________\nblock8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_30 (Add)                    (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n                                                                 add_29[0][0]                     \n__________________________________________________________________________________________________\nblock9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_30[0][0]                     \n__________________________________________________________________________________________________\nblock9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_31 (Add)                    (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n                                                                 add_30[0][0]                     \n__________________________________________________________________________________________________\nblock10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_31[0][0]                     \n__________________________________________________________________________________________________\nblock10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_32 (Add)                    (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n                                                                 add_31[0][0]                     \n__________________________________________________________________________________________________\nblock11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_32[0][0]                     \n__________________________________________________________________________________________________\nblock11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_33 (Add)                    (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n                                                                 add_32[0][0]                     \n__________________________________________________________________________________________________\nblock12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_33[0][0]                     \n__________________________________________________________________________________________________\nblock12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_34 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n                                                                 add_33[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_34[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 10, 10, 1024) 745472      add_34[0][0]                     \n__________________________________________________________________________________________________\nblock13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 10, 10, 1024) 4096        conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nadd_35 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n                                                                 batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nblock14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_35[0][0]                     \n__________________________________________________________________________________________________\nblock14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nglobal_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n==================================================================================================\nTotal params: 20,861,480\nTrainable params: 20,806,952\nNon-trainable params: 54,528\n__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXX28xAtQwhF"
      },
      "source": [
        "def create_model(name, input_shape=(227, 227, 3), freeze_upto=15):\n",
        "    base_model = tf.keras.applications.VGG16(\n",
        "        include_top=False, weights=\"imagenet\", input_shape=input_shape\n",
        "    )\n",
        "    for idx, layer in enumerate(base_model.layers):\n",
        "        if idx < freeze_upto:\n",
        "            layer.trainable = False\n",
        "        else:\n",
        "            layer.trainable = True\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=x, name=name)\n",
        "    return model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD7dGvZSUs4L"
      },
      "source": [
        "def CORAL(source_output, target_output, percent_lambda=0.75):\n",
        "\n",
        "    source_batch_size = tf.cast(tf.shape(source_output)[0], tf.float32)\n",
        "    target_batch_size = tf.cast(tf.shape(target_output)[0], tf.float32)\n",
        "    d = tf.cast(tf.shape(source_output)[1], tf.float32)\n",
        "\n",
        "    # Source covariance\n",
        "    xm = source_output - tf.reduce_mean(source_output, 0, keepdims=True)\n",
        "    xc = tf.matmul(tf.transpose(xm), xm) / source_batch_size\n",
        "\n",
        "    # Target covariance\n",
        "    xmt = target_output - tf.reduce_mean(target_output, 0, keepdims=True)\n",
        "    xct = tf.matmul(tf.transpose(xmt), xmt) / target_batch_size\n",
        "\n",
        "    # Frobenius norm\n",
        "    # loss = tf.sqrt(tf.reduce_sum(tf.multiply((xc - xct), (xc - xct))))\n",
        "    loss = tf.sqrt(tf.reduce_sum(tf.multiply((xc - xct), (xc - xct))))\n",
        "    loss = loss / (4 * d * d)\n",
        "    loss = percent_lambda * loss\n",
        "    # model.add_loss(loss)\n",
        "    return loss"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTLNOgsUYotC"
      },
      "source": [
        "def merged_model(\n",
        "    input_shape,\n",
        "    prune,\n",
        "    num_classes=31,\n",
        "    lambda_loss=0.75,\n",
        "    additional_loss=CORAL,\n",
        "    freeze_upto=15,\n",
        "):\n",
        "    source_model = create_model(\"source_fe\", input_shape, freeze_upto=15)\n",
        "    for layer in source_model.layers:\n",
        "        layer._name = layer.name + str(\"_1\")\n",
        "\n",
        "    if prune:\n",
        "        target_model = tfmot.sparsity.keras.prune_low_magnitude(\n",
        "            create_model(\"target_fe\", input_shape, freeze_upto), **cn.pruning_params\n",
        "        )\n",
        "    else:\n",
        "        target_model = create_model(\"target_fe\", input_shape, freeze_upto=15)\n",
        "\n",
        "    for layer in target_model.layers:\n",
        "        layer._name = layer.name + str(\"_2\")\n",
        "\n",
        "    prediction = layers.Dense(31, kernel_initializer=tf.initializers.RandomNormal(0, 0.005), name=\"prediction\")(source_model.output)\n",
        "    model = models.Model([source_model.input, target_model.input], prediction)\n",
        "\n",
        "    # additive_loss = additional_loss(\n",
        "    #     source_output=source_model.output,\n",
        "    #     target_output=target_model.output,\n",
        "    #     percent_lambda=lambda_loss,\n",
        "    # )\n",
        "\n",
        "    # model.add_loss(additive_loss)\n",
        "    # model.add_metric(additive_loss, name=\"domain_loss\")\n",
        "    return model\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPY4Ikz6sdce"
      },
      "source": [
        "def create_callbacks(my_dir=\"1_0.75\", LOGS_DIR=LOGS_DIR, save_weights=True, MODEL_PATH= MODEL_PATH):\r\n",
        "\r\n",
        "  callback_list = []\r\n",
        "  assert os.path.exists(LOGS_DIR), \"LOGS_DIR doesn't exist\"\r\n",
        "  experiment_logs_path = os.path.join(LOGS_DIR, my_dir)\r\n",
        "  Path(experiment_logs_path).mkdir(parents=True, exist_ok=True)\r\n",
        "  tb_logdir = os.path.join(LOGS_DIR, my_dir)\r\n",
        "  Path(tb_logdir).mkdir(parents=True, exist_ok=True)\r\n",
        "  assert os.path.exists(tb_logdir), \"tb_logdir doesn't exist\"\r\n",
        "  tb_logdir = os.path.join(\r\n",
        "      tb_logdir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "  )\r\n",
        "  log_dir = tb_logdir\r\n",
        "  # file_writer = tf.summary.create_file_writer(tb_logdir + \"/custom_evaluation\")\r\n",
        "  # file_writer.set_as_default()\r\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(tb_logdir, histogram_freq=1)\r\n",
        "  callback_list.append(tensorboard_callback)\r\n",
        "  tf.compat.v1.logging.info(f\"Tensorboard logs path: {tb_logdir}\")\r\n",
        "\r\n",
        "  \"\"\"CSV Logger Callback \"\"\"\r\n",
        "  Path(log_dir).mkdir(parents=True, exist_ok=True)\r\n",
        "  csv = os.path.join(log_dir, \"training_logs.csv\")\r\n",
        "  csv_logger = CSVLogger(\r\n",
        "      csv,\r\n",
        "      append=True,\r\n",
        "      separator=\";\",\r\n",
        "  )\r\n",
        "  tf.compat.v1.logging.info(f\"Model CSV logs path: {csv}\")\r\n",
        "  callback_list.append(csv_logger)\r\n",
        "\r\n",
        "  \"\"\"Reduce LR Callback \"\"\"\r\n",
        "  reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\r\n",
        "      monitor=\"val_accuracy\", factor=0.4, patience=2, min_lr=0.000001\r\n",
        "  )\r\n",
        "  callback_list.append(reduce_lr_callback)\r\n",
        "\r\n",
        "  \"\"\"Early Stopping Callback \"\"\"\r\n",
        "  early_stopping_callback = tf.keras.callbacks.EarlyStopping(\r\n",
        "      monitor=\"val_accuracy\",\r\n",
        "      patience=15,\r\n",
        "      verbose=1,\r\n",
        "      mode=\"auto\",\r\n",
        "  )\r\n",
        "  callback_list.append(early_stopping_callback)\r\n",
        "\r\n",
        "  \"\"\"Checkpoint Callback \"\"\"\r\n",
        "  if save_weights:\r\n",
        "      assert os.path.exists(MODEL_PATH), \"MODEL_PATH doesn't exist\"\r\n",
        "      checkpoint_path = os.path.join(\r\n",
        "          MODEL_PATH, (Path(log_dir).parent).name, Path(log_dir).name\r\n",
        "      )\r\n",
        "      Path(checkpoint_path).mkdir(parents=True, exist_ok=True)\r\n",
        "      assert os.path.exists(checkpoint_path), \"checkpoint_path doesn't exist\"\r\n",
        "      checkpoint_path = os.path.join(\r\n",
        "          checkpoint_path,\r\n",
        "          \"weights.{epoch:02d}-{val_accuracy:.2f}.hdf5\",\r\n",
        "      )\r\n",
        "      cp_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "          filepath=checkpoint_path,\r\n",
        "          save_weights_only=True,\r\n",
        "          save_best_only=True,\r\n",
        "          verbose=1,\r\n",
        "          monitor=\"val_accuracy\",\r\n",
        "      )\r\n",
        "      callback_list.append(cp_callback)\r\n",
        "\r\n",
        "  return callback_list, log_dir"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glZCCVOWc8fI"
      },
      "source": [
        "def loss_accuracy_plots(\r\n",
        "    hist,\r\n",
        "    log_dir,\r\n",
        "):\r\n",
        "    accuracy = hist.history[\"accuracy\"]\r\n",
        "    val_accuracy = hist.history[\"val_accuracy\"]\r\n",
        "    loss = hist.history[\"loss\"]\r\n",
        "    val_loss = hist.history[\"val_loss\"]\r\n",
        "    plt.figure(figsize=(18, 8))\r\n",
        "    plt.subplot(1, 2, 1)\r\n",
        "    plt.plot(loss, \"r\", label=\"Training\")\r\n",
        "    plt.plot(val_loss, \"r:\", label=\"Validation\")\r\n",
        "    plt.legend()\r\n",
        "    plt.title(\"Training and Validation Loss\")\r\n",
        "    plt.xlabel(\"Epochs\")\r\n",
        "    plt.ylabel(\"Loss\")\r\n",
        "\r\n",
        "    plt.subplot(1, 2, 2)\r\n",
        "    plt.plot(accuracy, \"g\", label=\"Training\")\r\n",
        "    plt.plot(val_accuracy, \"g:\", label=\"Validation\")\r\n",
        "    plt.legend()\r\n",
        "    plt.title(\"Training and Validation Accuracy\")\r\n",
        "    plt.xlabel(\"Epochs\")\r\n",
        "    plt.ylabel(\"Accuracy\")\r\n",
        "    plot_path = os.path.join(\r\n",
        "        EVALUATION, (Path(log_dir).parent).name, Path(log_dir).name\r\n",
        "    )\r\n",
        "    Path(plot_path).mkdir(parents=True, exist_ok=True)\r\n",
        "    tf.compat.v1.logging.info(\"Plots created at: \" + plot_path)\r\n",
        "    plot_path = os.path.join(plot_path, \"Accuracy_Loss_Plots.png\")\r\n",
        "    plt.savefig(plot_path)\r\n",
        "    plt.show()\r\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLHR1ZrYvmn3"
      },
      "source": [
        " def save_model(MODEL_PATH, log_dir):\r\n",
        "    tf.compat.v1.logging.info(\"Saving the model...\")\r\n",
        "    model_path = os.path.join(\r\n",
        "        MODEL_PATH, (Path(log_dir).parent).name, Path(log_dir).name\r\n",
        "    )\r\n",
        "    Path(model_path).mkdir(parents=True, exist_ok=True)\r\n",
        "    model.save(os.path.join(model_path, \"model.h5\"))\r\n",
        "    tf.compat.v1.logging.info(f\"Model successfully saved at: {model_path}\")\r\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEfq7AUQYjLW"
      },
      "source": [
        "## Run 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nphha0sJPEGT"
      },
      "source": [
        "temp_plot = create_model(\"VGG16\")\r\n",
        "plot_model(temp_plot, \"FeatureExtractors.png\", show_shapes=True, expand_nested=False)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "xx = source_ds.batch(32).prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = tf.keras.applications.VGG16(\n",
        "    include_top=False, weights=\"imagenet\", input_shape=(227,227,3)\n",
        ")\n",
        "for idx, layer in enumerate(base_model.layers):\n",
        "    if idx < 15:\n",
        "        layer.trainable = False\n",
        "    else:\n",
        "        layer.trainable = True\n",
        "\n",
        "inputs = tf.keras.Input(shape=(227,227,3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = tf.keras.layers.Dense(31, kernel_initializer=initializer, activation = \"softmax\")(x)\n",
        "mdl = tf.keras.models.Model(inputs=inputs, outputs=x, name=\"Testing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Testing\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_23 (InputLayer)        [(None, 227, 227, 3)]     0         \n_________________________________________________________________\nvgg16 (Functional)           (None, 7, 7, 512)         14714688  \n_________________________________________________________________\nglobal_average_pooling2d_10  (None, 512)               0         \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 31)                15903     \n=================================================================\nTotal params: 14,730,591\nTrainable params: 7,095,327\nNon-trainable params: 7,635,264\n_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "mdl.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "     26/Unknown - 21s 816ms/step - loss: 3.4603 - accuracy: 0.0276"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-6218ef0f0e0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmdlhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m mdlhist = mdl.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "mdlhist = None\n",
        "mdlhist = mdl.fit(\n",
        "    xx,\n",
        "    epochs=20,\n",
        "    verbose=1,\n",
        "    callbacks=callback_list,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "22/89 [======>.......................] - ETA: 53s - loss: 4.8472 - accuracy: 0.0398"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-a88d8a65b387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmdlhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m mdlhist = mdl.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5b1IHg2iImu"
      },
      "source": [
        "run2 = merged_model(\n",
        "          input_shape=(227, 227, 3),\n",
        "          num_classes=31,\n",
        "          lambda_loss=0.75,\n",
        "          additional_loss=CORAL,\n",
        "          prune=False,\n",
        "          freeze_upto=15,\n",
        "      )\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GHYAhr748iH"
      },
      "source": [
        "run2.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"functional_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2_1 (InputLayer)          [(None, 227, 227, 3) 0                                            \n__________________________________________________________________________________________________\nvgg16_1 (Functional)            (None, 7, 7, 512)    14714688    input_2_1[0][0]                  \n__________________________________________________________________________________________________\nglobal_average_pooling2d_1 (Glo (None, 512)          0           vgg16_1[0][0]                    \n__________________________________________________________________________________________________\ninput_4_2 (InputLayer)          [(None, 227, 227, 3) 0                                            \n__________________________________________________________________________________________________\nprediction (Dense)              (None, 31)           15903       global_average_pooling2d_1[0][0] \n==================================================================================================\nTotal params: 14,730,591\nTrainable params: 7,095,327\nNon-trainable params: 7,635,264\n__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfvMEhJnQLNY"
      },
      "source": [
        "# plot_model(model, \"DDAN.png\", show_shapes=True, expand_nested=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzsCmStsj4Ok"
      },
      "source": [
        "run2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=\"accuracy\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiRlbPOk2TJZ"
      },
      "source": [
        "callback_list, log_dir = create_callbacks(\"1_0.75\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Tensorboard logs path: /root/Master-Thesis/logs/1_0.75/20210122-233820\n",
            "INFO:tensorflow:Model CSV logs path: /root/Master-Thesis/logs/1_0.75/20210122-233820/training_logs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9o4DtQmjsST"
      },
      "source": [
        "run2hist = None\n",
        "run2hist = run2.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_test,\n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    callbacks=callback_list,\n",
        ")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            " 1/89 [..............................] - ETA: 0s - loss: 3.5489 - accuracy: 0.0312WARNING:tensorflow:From /opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "53/89 [================>.............] - ETA: 30s - loss: 3.5391 - accuracy: 0.0377"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-7858ad33b11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrun2hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m run2hist = run2.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MSWP2Id5J8s"
      },
      "source": [
        "loss_accuracy_plots(\r\n",
        "        hist=hist2,\r\n",
        "        log_dir=log_dir,\r\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxx8lv3FdKo2"
      },
      "source": [
        "loss_accuracy_plots(\r\n",
        "        hist=run1hist,\r\n",
        "        log_dir=log_dir,\r\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU_cv0zVu_rN"
      },
      "source": [
        "## Run 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO6tzMA2D_o1"
      },
      "source": [
        "# for layer in modell.get_layer(\"Target\").layers:\n",
        "#         print(layer._name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OPD1bm8BNOM"
      },
      "source": [
        "# for idx, layers in enumerate(model.layers):\n",
        "#   print(idx, layers.name)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}